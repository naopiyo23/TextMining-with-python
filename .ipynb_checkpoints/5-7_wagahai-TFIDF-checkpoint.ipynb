{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDFは重要語の抽出に使われる。\n",
    "ある文章を特徴づけるような重要語は、テキストを検索するときのキーワードマッチングや、テキスト要約の骨格にするなど様々な用途がある。\n",
    "出現頻度順に単語を並べると、「こと」や「とき」のようなどの文章でも頻繁に使われる言葉が並ぶが、これらはその文章を特徴づける重要語とは言えない。\n",
    "\n",
    "そこで、出現頻度は高いが、その語を含む文章は少ない単語を、重要と判定する考え方であるTF-IDFが重要語の抽出に利用されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF（Term Frequency）は文書中の単語の出現頻度を表す。例えば弊社紹介ページが1000単語で構成されていて、「人材」という単語が3回出現していたら、TF=3/1000=0.003となる。\n",
    "\n",
    "一方IDF（Inverse Document Frequency）は逆文書頻度を表す。定義によるとIDFは、「対象とする総文書数」を「ある単語を含む文書数」で割ったものの対数である。すなわちIDFは「ある単語の文書への現れにくさ（レア度）」を表している。すべての文書に出現するような単語はIDF=log(1)=0となるし、例えば「人材」という単語が100文書中の1文書に出現するとするとIDF=log(100)=2となる。要するに単語の出現しにくさを桁数で表したようなもの。（ここでは解釈しやすいよう、常用対数としている。対数の底が何であれ結果は定数倍にしかならない。）\n",
    "\n",
    "TF-IDFはこのTFとIDFの積で定義されるので、「ある文書で多く使われている単語のうち、他の文書ではあまり使われていない単語」が大きな値をとる。したがって１つの文書を構成する全単語から、TF-IDFの大きいものをいくつか選択することで、その文書を特徴づける単語を抽出することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の例では、単語を単位としているが、その他、文字、句でも重要度の対象として成り立つ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['吾輩 は 猫 で ある', '名前 は まだ 無い', 'どこ で 生れ た か とんと 見当 が つか ぬ'],\n",
       "      dtype='<U686')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# リスト 5-7 『吾輩は猫である』の先頭 3 文の TF-IDF を求めるプ\n",
    "import re\n",
    "import numpy as np\n",
    "import MeCab\n",
    "from aozora import Aozora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "aozora = Aozora(\"wagahaiwa_nekodearu.txt\")# 文に分解する\n",
    "string = '\\n'.join(aozora.read())\n",
    "string = re.sub('　', '', string)\n",
    "string = re.split('。(?!」)|\\n', re.sub('　', '', string))\n",
    "while '' in string:  string.remove('')  # 空行を除く\n",
    "m = MeCab.Tagger(\"-Owakati\")            # MeCabで分かち書きにする\n",
    "wakatilist = []\n",
    "for sentense in string:\n",
    "    # 文末に挿入される改行をrstripで除去する\n",
    "    wakatilist.append(m.parse(sentense).rstrip())\n",
    "\n",
    "wakatilist = np.array(wakatilist)  # scikit-learnの入力とするためにNumPyのnarrayに変換\n",
    "wakatilist = wakatilist[3:6]       # 先頭の3行分だけを入力にする\n",
    "wakatilist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69314718 0.         0.         0.         0.         1.28768207\n",
      "  0.         0.         0.         1.28768207 0.         0.\n",
      "  1.69314718 0.         1.69314718 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.28768207 1.69314718 1.69314718\n",
      "  0.         1.69314718 0.         0.         0.        ]\n",
      " [0.         1.69314718 1.69314718 1.69314718 1.69314718 1.28768207\n",
      "  1.69314718 1.69314718 1.69314718 0.         0.         0.\n",
      "  0.         0.         0.         1.69314718 1.69314718]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, norm=None, \\\n",
    "                             token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "# norm=Noneは、出力を行ごとのベクトルと見たときに長さを1にする（正規化）処理をしないように指定\n",
    "tfidf = vectorizer.fit_transform(wakatilist)\n",
    "print(tfidf.toarray())             # 出力を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各企業の採用サイト毎で違いを見てみるとか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://qiita.com/tfujiwar/items/8ea43aaaebf2ee7cf335"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
