{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNetによる類語検索\n",
    "**概念**  \n",
    "- synset：同義語のグループ。synsetは概念の関係（e.g. 上位概念、下位概念、部分関係、論理的含意）でお互いにリンクされている。  \n",
    "  \n",
    "**日本語版WordNetについて**  \n",
    "Open Multilingual WordNetには、英語版WordNetのsynsetに対して、対応する訳語が用意されている。\n",
    "- 語からsynsetへの変換の部分で、日本語入力が可能\n",
    "- 日本語出力が可能になる\n",
    "  \n",
    "**使い方**  \n",
    "NLTKからWordNetへアクセスするときは、WordNetパッケージをダウンロードする必要がある。以下、手順。  \n",
    "ダウンロードしているかどうかも下記コード実行時のUIから確認可能。\n",
    "\n",
    ">import nltk  \n",
    ">nltk.download()  \n",
    "\n",
    "Corporaタブ → wordnet & wordnet_ic  \n",
    "または\n",
    "Collectionsタブ → all-Corpusでも可能。（こっちはダウンロードに時間がかかる。）}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('whale.n.02')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 日本語版WordNet：Open Multilingual WordNet\n",
    "from nltk.corpus import wordnet as wn\n",
    "# synsetを日本語で検索する。\n",
    "wn.synsets('鯨', lang='jpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['いぬ',\n",
       " 'スパイ',\n",
       " '回者',\n",
       " '回し者',\n",
       " '密偵',\n",
       " '工作員',\n",
       " '廻者',\n",
       " '廻し者',\n",
       " '探',\n",
       " '探り',\n",
       " '犬',\n",
       " '秘密捜査員',\n",
       " 'まわし者',\n",
       " '諜報員',\n",
       " '諜者',\n",
       " '間者',\n",
       " '間諜',\n",
       " '隠密']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synsetに対応するlemmaを表示する時に日本語表示にする。\n",
    "wn.synset('spy.n.01').lemma_names('jpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ミカンの上位概念： [Synset('citrus.n.01')]\n",
      "ミカンの下位概念： [Synset('bitter_orange.n.02'), Synset('sweet_orange.n.01'), Synset('temple_orange.n.02')]\n",
      "ミカンとリンゴの共通項： [Synset('edible_fruit.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# WordNetの使い方：S.hoge()\n",
    "orange = wn.synsets('ミカン', lang='jpn')[0]\n",
    "print('ミカンの上位概念：', orange.hypernyms())\n",
    "print('ミカンの下位概念：', orange.hyponyms())\n",
    "\n",
    "apple = wn.synsets('リンゴ', lang='jpn')[0]\n",
    "print('ミカンとリンゴの共通項：', orange.lowest_common_hypernyms(apple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move.v.15 v verb.competition\n",
      "['move', 'go']\n",
      "have a turn; make one's move in a game\n",
      "['Can I go now?']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# リスト 5-12  英文 WordNet を NLTK から利用するプログラム\n",
    "# NLTK パッケージのファイル wordnet.py に含まれているデモプログラムから抜粋\n",
    "#\n",
    "# 前準備\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus.reader import WordNetCorpusReader, WordNetICCorpusReader\n",
    "wn = WordNetCorpusReader(nltk.data.find('corpora/wordnet'), None)\n",
    "S = wn.synset\n",
    "L = wn.lemma\n",
    "\n",
    "# synsetの基本メソッド\n",
    "s = S('go.v.21')        # 単語goの動詞の21番のsynsetを読み出す\n",
    "# synsetの名前がmove.v.15 pos（品詞名）がv 辞書ファイルがverb.competition\n",
    "print(s.name(), s.pos(), s.lexname())\n",
    "print(s.lemma_names())  # synset goの語彙は['move', 'go']\n",
    "print(s.definition())   # goの定義は\"have a turn; make one's move in a game\"\n",
    "print(s.examples())     # goの例文は['Can I go now?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "[Lemma('atomic_warhead.n.01.nuke')]\n",
      "[Lemma('atomization.n.02.atomization')]\n"
     ]
    }
   ],
   "source": [
    "# リンクをたどってみる\n",
    "s = S('dog.n.01')\n",
    "print(s.hypernyms())\n",
    "    # dogの上位概念は[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
    "print(L('zap.v.03.nuke').derivationally_related_forms())\n",
    "    # [Lemma('atomic_warhead.n.01.nuke')]\n",
    "print(L('zap.v.03.atomize').derivationally_related_forms())\n",
    "    # [Lemma('atomization.n.02.atomization')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canis.n.01'), Synset('pack.n.06')]\n",
      "[Synset('flag.n.07')]\n",
      "[Synset('writer.n.01')]\n",
      "[Synset('ambrose.n.01'), Synset('bach.n.01'), Synset('barber.n.01'), Synset('bartok.n.01'), Synset('beethoven.n.01'), Synset('bellini.n.01'), Synset('berg.n.02'), Synset('berlioz.n.01'), Synset('bernstein.n.01'), Synset('bizet.n.01'), Synset('blitzstein.n.01'), Synset('bloch.n.01'), Synset('borodin.n.01'), Synset('boulez.n.01'), Synset('brahms.n.01'), Synset('britten.n.01'), Synset('bruch.n.01'), Synset('bruckner.n.01'), Synset('byrd.n.01'), Synset('cage.n.03'), Synset('chavez.n.01'), Synset('cherubini.n.01'), Synset('chopin.n.03'), Synset('copland.n.01'), Synset('corelli.n.01'), Synset('couperin.n.01'), Synset('coward.n.02'), Synset('czerny.n.01'), Synset('debussy.n.01'), Synset('delibes.n.01'), Synset('delius.n.01'), Synset('donizetti.n.01'), Synset('dowland.n.01'), Synset('dukas.n.01'), Synset('dvorak.n.01'), Synset('elgar.n.01'), Synset('enesco.n.01'), Synset('falla.n.01'), Synset('franck.n.01'), Synset('gershwin.n.02'), Synset('glinka.n.01'), Synset('gluck.n.01'), Synset('gounod.n.01'), Synset('grainger.n.01'), Synset('grieg.n.01'), Synset('halevy.n.01'), Synset('handel.n.01'), Synset('handy.n.01'), Synset('haydn.n.01'), Synset('hindemith.n.01'), Synset('honegger.n.01'), Synset('humperdinck.n.01'), Synset('ibert.n.01'), Synset('ives.n.01'), Synset('joachim.n.01'), Synset('joplin.n.02'), Synset('kachaturian.n.01'), Synset('kern.n.01'), Synset('khachaturian.n.01'), Synset('lambert.n.02'), Synset('lasso.n.01'), Synset('ledbetter.n.01'), Synset('lehar.n.01'), Synset('liszt.n.01'), Synset('lloyd_webber.n.01'), Synset('loewe.n.01'), Synset('lully.n.02'), Synset('macdowell.n.01'), Synset('mahler.n.01'), Synset('massenet.n.01'), Synset('mendelssohn.n.01'), Synset('menotti.n.01'), Synset('meyerbeer.n.01'), Synset('milhaud.n.01'), Synset('monteverdi.n.01'), Synset('moore.n.01'), Synset('mozart.n.01'), Synset('mussorgsky.n.01'), Synset('nielsen.n.01'), Synset('offenbach.n.01'), Synset('orbison.n.01'), Synset('palestrina.n.01'), Synset('piston.n.01'), Synset('porter.n.04'), Synset('poulenc.n.01'), Synset('prokofiev.n.01'), Synset('puccini.n.01'), Synset('purcell.n.01'), Synset('rachmaninoff.n.01'), Synset('rameau.n.01'), Synset('ravel.n.01'), Synset('reich.n.03'), Synset('respighi.n.01'), Synset('rimsky-korsakov.n.01'), Synset('rodgers.n.01'), Synset('romberg.n.01'), Synset('rossini.n.01'), Synset('rubinstein.n.02'), Synset('saint-saens.n.01'), Synset('satie.n.01'), Synset('schnabel.n.01'), Synset('schonberg.n.01'), Synset('schubert.n.01'), Synset('schumann.n.01'), Synset('schumann.n.02'), Synset('scriabin.n.01'), Synset('segovia.n.01'), Synset('sessions.n.01'), Synset('shostakovich.n.01'), Synset('sibelius.n.01'), Synset('smetana.n.01'), Synset('sondheim.n.01'), Synset('sousa.n.01'), Synset('strauss.n.01'), Synset('strauss.n.02'), Synset('strauss.n.03'), Synset('stravinsky.n.01'), Synset('sullivan.n.05'), Synset('tallis.n.01'), Synset('taylor.n.01'), Synset('tchaikovsky.n.01'), Synset('telemann.n.01'), Synset('thomson.n.01'), Synset('varese.n.01'), Synset('vaughan_williams.n.01'), Synset('verdi.n.01'), Synset('villa-lobos.n.01'), Synset('vivaldi.n.01'), Synset('wagner.n.02'), Synset('walton.n.01'), Synset('weber.n.05'), Synset('weill.n.01'), Synset('wolf.n.02')]\n"
     ]
    }
   ],
   "source": [
    "print(s.member_holonyms())  # [Synset('canis.n.01'), Synset('pack.n.06')]\n",
    "print(s.part_meronyms())    # [Synset('flag.n.07')]\n",
    "print(S('Austen.n.1').instance_hypernyms())\n",
    "    # Austenが例であるような上位概念[Synset('writer.n.01')]\n",
    "print(S('composer.n.1').instance_hyponyms())\n",
    "    # 作家の例（作曲家が多数表示される）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('professor.n.01')]\n",
      "[Synset('crew.n.01')]\n",
      "[Synset('leg.n.03'), Synset('tabletop.n.01'), Synset('tableware.n.01')]\n",
      "[Synset('meal.n.01')]\n",
      "[Synset('hydrogen.n.01'), Synset('oxygen.n.01')]\n",
      "[Synset('gin_and_it.n.01'), Synset('gin_and_tonic.n.01'), Synset('martini.n.01'), Synset('pink_lady.n.01')]\n",
      "[Synset('sleep.v.01')]\n",
      "[Synset('dense.s.03'), Synset('doughy.s.01'), Synset('heavier-than-air.s.01'), Synset('hefty.s.02'), Synset('massive.s.04'), Synset('non-buoyant.s.01'), Synset('ponderous.s.02')]\n",
      "[Synset('weight.n.01')]\n",
      "[Synset('weight.n.01')]\n",
      "[Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print(S('faculty.n.2').member_meronyms())\n",
    "    # 一部分（メンバー）[Synset('professor.n.01')]\n",
    "print(S('copilot.n.1').member_holonyms())\n",
    "    # これが含まれる大きな集合[Synset('crew.n.01')]\n",
    "print(S('table.n.2').part_meronyms())\n",
    "    # 一部分[Synset('leg.n.03'), Synset('tabletop.n.01'), Synset('tableware.n.01')]\n",
    "print(S('course.n.7').part_holonyms())  # 含まれる集合[Synset('meal.n.01')]\n",
    "print(S('water.n.1').substance_meronyms())\n",
    "    # 一部分（材料）[Synset('hydrogen.n.01'), Synset('oxygen.n.01')]\n",
    "print(S('gin.n.1').substance_holonyms())  # 含まれる集合（材料）\n",
    "    # [Synset('gin_and_it.n.01'), Synset('gin_and_tonic.n.01'),\n",
    "    #  Synset('martini.n.01'), Synset('pink_lady.n.01')]\n",
    "print(S('snore.v.1').entailments())  # 論理的な結論[Synset('sleep.v.01')]\n",
    "print(S('heavy.a.1').similar_tos()) \n",
    "    #  [Synset('dense.s.03'), Synset('doughy.s.01'), Synset('heavier-than-air.s.01'),\n",
    "    #   Synset('hefty.s.02'), Synset('massive.s.04'), Synset('non-buoyant.s.01'),\n",
    "    #   Synset('ponderous.s.02')]\n",
    "print(S('light.a.1').attributes())            # 属性[Synset('weight.n.01')]\n",
    "print(S('heavy.a.1').attributes())            # 属性[Synset('weight.n.01')]\n",
    "\n",
    "print(S('person.n.01').root_hypernyms())\n",
    "    # 意味トリーのルート[Synset('entity.n.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('organism.n.01')]\n",
      "[Synset('woman.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# 二者の関係（二者の間で初めて共通する概念）\n",
    "print(S('person.n.01').lowest_common_hypernyms(S('dog.n.01')))  # 初めて共通する概念\n",
    "    # 結果は[Synset('organism.n.01')]\n",
    "print(S('woman.n.01').lowest_common_hypernyms(S('girlfriend.n.02')))\n",
    "    # 結果は[Synset('woman.n.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.3333333333333333\n",
      "2.0281482472922856\n",
      "0.8571428571428571\n",
      "0.4497755285516739\n",
      "0.8863288628086228\n",
      "[Synset('computer_science.n.01')]\n",
      "[Synset('india.n.01')]\n",
      "[Synset('slang.n.02')]\n"
     ]
    }
   ],
   "source": [
    "# 類似性指標。以下の指標の説明は、NLTKのドキュメント\n",
    "# http://www.nltk.org/howto/wordnet.htmlにある\n",
    "print(S('dog.n.01').path_similarity(S('cat.n.01')))   # パスで見たノードの近さ0.2\n",
    "print(S('dog.n.01').path_similarity(S('wolf.n.01')))  # パスで見たノードの近さ0.333\n",
    "print(S('dog.n.01').lch_similarity(S('cat.n.01')))\n",
    "    # Leacock-Chosorowの類似度2.028\n",
    "print(S('dog.n.01').wup_similarity(S('cat.n.01')))  # Wu-Palmer Similarity 0.857\n",
    "wnic = WordNetICCorpusReader(nltk.data.find('corpora/wordnet_ic'), '.*\\.dat')\n",
    "ic = wnic.ic('ic-brown.dat')\n",
    "print(S('dog.n.01').jcn_similarity(S('cat.n.01'), ic))\n",
    "    # Information ContentによるJiang-Conrathの類似度0.4498\n",
    "ic = wnic.ic('ic-semcor.dat')\n",
    "print(S('dog.n.01').lin_similarity(S('cat.n.01'), ic))\n",
    "    # Information ContentによるLinの類似度0.8863\n",
    "\n",
    "print(S('code.n.03').topic_domains())\n",
    "    # topic domain [Synset('computer_science.n.01')]\n",
    "print(S('pukka.a.01').region_domains())  # region domain [Synset('india.n.01')]\n",
    "print(S('freaky.a.01').usage_domains())  # usage domain [Synset('slang.n.02')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
